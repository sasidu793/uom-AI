{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Housing Price Prediction Model\n",
    "\n",
    "This notebook implements and compares two regression models for predicting housing prices:\n",
    "- Linear Regression\n",
    "- Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('Housing.csv')\n",
    "\n",
    "# Display basic information\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nDataset info:\")\n",
    "print(df.info())\n",
    "print(\"\\nStatistical summary:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "### Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "categorical_cols = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', \n",
    "                    'airconditioning', 'prefarea', 'furnishingstatus']\n",
    "\n",
    "le = LabelEncoder()\n",
    "df_encoded = df.copy()\n",
    "\n",
    "for col in categorical_cols:\n",
    "    df_encoded[col] = le.fit_transform(df[col])\n",
    "\n",
    "print(\"\\nEncoded dataset:\")\n",
    "print(df_encoded.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data into Train, Validation, and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df_encoded.drop('price', axis=1)\n",
    "y = df_encoded['price']\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set size: {X_train.shape[0]}\")\n",
    "print(f\"Validation set size: {X_val.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization\n",
    "\n",
    "### Target Variable Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the target variable distribution\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(y, bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of House Prices')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(df['area'], df['price'], alpha=0.5)\n",
    "plt.xlabel('Area (sq ft)')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Price vs Area')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "correlation_matrix = df_encoded.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            fmt='.2f', linewidths=0.5)\n",
    "plt.title('Correlation Matrix of Features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate_model(y_true, y_pred, dataset_name):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\n{dataset_name} Results:\")\n",
    "    print(f\"MSE: {mse:,.2f}\")\n",
    "    print(f\"RMSE: {rmse:,.2f}\")\n",
    "    print(f\"MAE: {mae:,.2f}\")\n",
    "    print(f\"R² Score: {r2:.4f}\")\n",
    "    \n",
    "    return mse, rmse, mae, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"LINEAR REGRESSION MODEL\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred_lr = lr_model.predict(X_train)\n",
    "y_val_pred_lr = lr_model.predict(X_val)\n",
    "y_test_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "lr_train_metrics = evaluate_model(y_train, y_train_pred_lr, \"Training Set\")\n",
    "lr_val_metrics = evaluate_model(y_val, y_val_pred_lr, \"Validation Set\")\n",
    "lr_test_metrics = evaluate_model(y_test, y_test_pred_lr, \"Test Set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RANDOM FOREST REGRESSOR MODEL\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred_rf = rf_model.predict(X_train)\n",
    "y_val_pred_rf = rf_model.predict(X_val)\n",
    "y_test_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "rf_train_metrics = evaluate_model(y_train, y_train_pred_rf, \"Training Set\")\n",
    "rf_val_metrics = evaluate_model(y_val, y_val_pred_rf, \"Validation Set\")\n",
    "rf_test_metrics = evaluate_model(y_test, y_test_pred_rf, \"Test Set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance (Random Forest)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Feature Importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance['feature'], feature_importance['importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importance (Random Forest)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions vs Actual Values Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions vs actual values\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Linear Regression - Validation Set\n",
    "axes[0, 0].scatter(y_val, y_val_pred_lr, alpha=0.5)\n",
    "axes[0, 0].plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], \n",
    "                'r--', lw=2)\n",
    "axes[0, 0].set_xlabel('Actual Price')\n",
    "axes[0, 0].set_ylabel('Predicted Price')\n",
    "axes[0, 0].set_title(f'Linear Regression - Validation Set\\nR² = {lr_val_metrics[3]:.4f}')\n",
    "\n",
    "# Linear Regression - Test Set\n",
    "axes[0, 1].scatter(y_test, y_test_pred_lr, alpha=0.5)\n",
    "axes[0, 1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "                'r--', lw=2)\n",
    "axes[0, 1].set_xlabel('Actual Price')\n",
    "axes[0, 1].set_ylabel('Predicted Price')\n",
    "axes[0, 1].set_title(f'Linear Regression - Test Set\\nR² = {lr_test_metrics[3]:.4f}')\n",
    "\n",
    "# Random Forest - Validation Set\n",
    "axes[1, 0].scatter(y_val, y_val_pred_rf, alpha=0.5, color='green')\n",
    "axes[1, 0].plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], \n",
    "                'r--', lw=2)\n",
    "axes[1, 0].set_xlabel('Actual Price')\n",
    "axes[1, 0].set_ylabel('Predicted Price')\n",
    "axes[1, 0].set_title(f'Random Forest - Validation Set\\nR² = {rf_val_metrics[3]:.4f}')\n",
    "\n",
    "# Random Forest - Test Set\n",
    "axes[1, 1].scatter(y_test, y_test_pred_rf, alpha=0.5, color='green')\n",
    "axes[1, 1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "                'r--', lw=2)\n",
    "axes[1, 1].set_xlabel('Actual Price')\n",
    "axes[1, 1].set_ylabel('Predicted Price')\n",
    "axes[1, 1].set_title(f'Random Forest - Test Set\\nR² = {rf_test_metrics[3]:.4f}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Linear Regression residuals\n",
    "residuals_lr = y_test - y_test_pred_lr\n",
    "axes[0].scatter(y_test_pred_lr, residuals_lr, alpha=0.5)\n",
    "axes[0].axhline(y=0, color='r', linestyle='--')\n",
    "axes[0].set_xlabel('Predicted Price')\n",
    "axes[0].set_ylabel('Residuals')\n",
    "axes[0].set_title('Residual Plot - Linear Regression')\n",
    "\n",
    "# Random Forest residuals\n",
    "residuals_rf = y_test - y_test_pred_rf\n",
    "axes[1].scatter(y_test_pred_rf, residuals_rf, alpha=0.5, color='green')\n",
    "axes[1].axhline(y=0, color='r', linestyle='--')\n",
    "axes[1].set_xlabel('Predicted Price')\n",
    "axes[1].set_ylabel('Residuals')\n",
    "axes[1].set_title('Residual Plot - Random Forest')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model comparison\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL COMPARISON (Test Set)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'Model': ['Linear Regression', 'Random Forest'],\n",
    "    'RMSE': [lr_test_metrics[1], rf_test_metrics[1]],\n",
    "    'MAE': [lr_test_metrics[2], rf_test_metrics[2]],\n",
    "    'R² Score': [lr_test_metrics[3], rf_test_metrics[3]]\n",
    "})\n",
    "\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on New Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on a new sample\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PREDICTION ON NEW SAMPLE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "new_sample_idx = 0\n",
    "new_sample = X_test.iloc[new_sample_idx:new_sample_idx+1]\n",
    "actual_price = y_test.iloc[new_sample_idx]\n",
    "\n",
    "lr_prediction = lr_model.predict(new_sample)[0]\n",
    "rf_prediction = rf_model.predict(new_sample)[0]\n",
    "\n",
    "print(f\"\\nSample features:\")\n",
    "print(new_sample)\n",
    "print(f\"\\nActual Price: {actual_price:,.0f}\")\n",
    "print(f\"Linear Regression Prediction: {lr_prediction:,.0f}\")\n",
    "print(f\"Random Forest Prediction: {rf_prediction:,.0f}\")\n",
    "print(f\"Linear Regression Error: {abs(actual_price - lr_prediction):,.0f}\")\n",
    "print(f\"Random Forest Error: {abs(actual_price - rf_prediction):,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "plt.figure(figsize=(8, 6))\n",
    "models = ['Actual', 'Linear\\nRegression', 'Random\\nForest']\n",
    "values = [actual_price, lr_prediction, rf_prediction]\n",
    "colors = ['blue', 'orange', 'green']\n",
    "\n",
    "bars = plt.bar(models, values, color=colors, alpha=0.7, edgecolor='black')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Price Prediction Comparison')\n",
    "plt.ylim([0, max(values) * 1.2])\n",
    "\n",
    "for bar, value in zip(bars, values):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{value:,.0f}',\n",
    "             ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
